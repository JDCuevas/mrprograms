package edu.uprm.cse.bigdata.mrtwo;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;
import twitter4j.Status;
import twitter4j.TwitterException;
import twitter4j.TwitterObjectFactory;
import java.util.HashSet;
import java.util.Set;
import java.util.Arrays;

import java.io.IOException;

/**
 * Created by julian_cuevas1 on 10/17/18.
 */
public class TwitterKeyWordMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
    @Override
    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        String rawTweet = value.toString();

        try {
            Status status = TwitterObjectFactory.createStatus(rawTweet);
            String tweet = status.getText().toUpperCase();
	   
	    
	    public Set<String> stopWordSet = new HashSet<String>(Arrays.asList(stopwords));
            public Set<String> stopWordSet2 = new HashSet<String>(Arrays.asList(stopwords2));

	    public boolean isStopword(String word) {
		if(word.length() < 2) return true;
		if(word.charAt(0) >= '0' && word.charAt(0) <= '9') return true; //remove numbers, "25th", etc
		if(stopWordSet.contains(word)) return true;
		if(stopWordSet2.contains(word)) return true;
		else return false;
	    }	

            /*if (isStopword(tweet)){
	        context.write(new Text("NotStopWords:"), new IntWritable(1));
	    }*/
                
        }catch(TwitterException e){

        }

    }
}
